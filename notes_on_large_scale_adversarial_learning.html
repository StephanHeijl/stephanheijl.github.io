<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Notes on BigBiGAN - Stephan Heijl</title>
    <meta name="description" content="A detailed examination of Large Scale Adversarial Representation Learning (BigBiGAN).">
    <link href="https://fonts.googleapis.com/css2?family=Newsreader:ital,opsz,wght@0,6..72,400;0,6..72,500;1,6..72,400&family=Outfit:wght@300;400;500;600&family=JetBrains+Mono:wght@400&display=swap" rel="stylesheet">
    <link rel="stylesheet" href="style-v2.css">
    <style>
        .article-content pre {
            background: var(--bg-dark);
            color: #f6f8ff;
            padding: 1.5rem;
            overflow-x: auto;
            margin: 2rem 0;
            font-family: 'JetBrains Mono', monospace;
            font-size: 0.85rem;
        }
    </style>
</head>
<body>
    <!-- Progress Bar -->
    <div class="progress-bar" id="progressBar"></div>

    <!-- Navigation -->
    <nav>
        <a href="index.html" class="logo">Stephan Heijl</a>
        <ul class="nav-links">
            <li><a href="projects.html">Work</a></li>
            <li><a href="projects.html#posts">Writing</a></li>
            <li><a href="projects.html#education">Background</a></li>
            <li><a href="contact.html">Contact</a></li>
        </ul>
    </nav>

    <!-- Article Header -->
    <header class="article-header">
        <div class="breadcrumb">
            <a href="index.html">Home</a>
            <span>-></span>
            <a href="projects.html#posts">Writing</a>
            <span>-></span>
            <span>Notes on BigBiGAN</span>
        </div>

        <div class="article-meta">
            <span class="meta-tag">Paper Notes</span>
            <span class="meta-item">Posted: July 16, 2019</span>
            <span class="meta-item">Updated: August 18, 2019</span>
        </div>

        <h1>Large Scale Adversarial Representation Learning Explained</h1>

        <p class="article-intro">
            This post dives into <a href="https://arxiv.org/abs/1907.02544">Large Scale Adversarial Representation
            Learning</a>, a paper from Google introducing BigBiGAN for self-supervised image classification.
        </p>
    </header>

    <!-- Article Content -->
    <article class="article-content">
        <h2>Introduction</h2>

        <p>
            BigBiGAN is a Generative Adversarial Network that includes representation learning methods to produce
            a high-quality self-supervised image classifier. Results match state-of-the-art unsupervised methods
            and approach AlexNet's supervised performance.
        </p>

        <h3>Why This Matters</h3>

        <p>
            This paper demonstrates effective <strong>transfer learning</strong>. Networks taught a specific task
            can be trivially adapted for another task, emphasizing generalizability across domains.
        </p>

        <figure class="article-figure">
            <img src="img/notes_on_lsarl/image10.jpg" alt="Andrew Ng on transfer learning"/>
            <figcaption>In 2017, Andrew Ng recognized transfer learning's value and unsupervised learning's potential</figcaption>
        </figure>

        <h2>Generative Adversarial Networks</h2>

        <p>
            GANs, invented in 2014 by Ian Goodfellow, generate images through an adversarial process. Two networks
            are created: a generator (creates images) and discriminator (distinguishes real from generated).
        </p>

        <h2>Representation Learning</h2>

        <p>
            Representation learning models a dataset's distribution to provide descriptive features. When used
            as a separate training stage with unsupervised techniques, it creates more "generic" representations
            useful for transfer learning.
        </p>

        <h2>Neural Network Architecture</h2>

        <p>
            BigBiGAN uses the generator and discriminator from BigGAN (state-of-the-art GAN) plus an encoder
            derived from BiGAN based on ResNet/RevNet.
        </p>

        <figure class="article-figure">
            <img src="img/notes_on_lsarl/image17.png" alt="BigBiGAN architecture"/>
            <figcaption>BigBiGAN architecture: red section from BiGAN, blue sections from BigGAN</figcaption>
        </figure>

        <h3>The Encoder</h3>

        <p>
            The encoder takes an image and generates a latent representation—the opposite of the GAN which takes
            latent representations and generates images. With optimal components, <code>E(G(E(x))) = E(x)</code>.
        </p>

        <h2>Results</h2>

        <h3>Encoder/Generator Quality</h3>

        <p>BigBiGAN clearly preserves semantic information in encoded images:</p>

        <ul>
            <li>Recognizable outputs</li>
            <li>Relevant elements in similar poses</li>
            <li>Color replication</li>
            <li>Handles partially cropped subjects</li>
        </ul>

        <figure class="article-figure">
            <img src="img/notes_on_lsarl/image13.jpg" alt="BigBiGAN generated images"/>
            <figcaption>BigBiGAN encoding results: top row is ground truth, bottom is reconstructed</figcaption>
        </figure>

        <h3>Classifier Performance</h3>

        <p>
            Using a logistic regression classifier on the latent representation with only 10,000 ImageNet samples
            achieved <strong>61% top-1 accuracy</strong> and <strong>81.9% top-5 accuracy</strong>—comparable to
            AlexNet (62.5%/83%) with less than 1% of the data.
        </p>

        <h2>Conclusion</h2>

        <p>
            BigBiGAN offers impressive advances in image encoding and efficient feature learning. Applications
            include generating initial latent states for GANs and pretraining networks where labeled data is
            scarce but unlabeled samples are abundant—particularly valuable in medical domains with privacy
            implications.
        </p>

        <h2>References</h2>

        <ul>
            <li><a href="https://arxiv.org/abs/1907.02544">Large Scale Adversarial Representation Learning</a></li>
            <li><a href="https://arxiv.org/abs/1512.03385">Deep Residual Learning for Image Recognition</a></li>
            <li><a href="https://arxiv.org/abs/1809.11096">Large Scale GAN Training (BigGAN)</a></li>
        </ul>
    </article>

    <!-- Article Footer -->
    <div class="article-footer">
        <a href="projects.html#posts" class="back-link">
            <svg width="20" height="20" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="1.5">
                <path d="M19 12H5M12 19l-7-7 7-7"/>
            </svg>
            Back to Writing
        </a>
    </div>

    <!-- Footer -->
    <footer>
        <p class="footer-text">© 2024 Stephan Heijl</p>
        <div class="footer-links">
            <a href="https://github.com/StephanHeijl">GitHub</a>
            <a href="https://linkedin.com/in/stephanheijl">LinkedIn</a>
            <a href="contact.html">Email</a>
        </div>
    </footer>

    <script>
        window.addEventListener('scroll', () => {
            const docHeight = document.documentElement.scrollHeight - window.innerHeight;
            const progress = (window.scrollY / docHeight) * 100;
            document.getElementById('progressBar').style.width = progress + '%';
        });
    </script>
</body>
</html>
