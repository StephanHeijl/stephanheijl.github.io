<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Visualizing Deep Learning Antibiotics - Stephan Heijl</title>
    <meta name="description" content="A blog post visualizing and explaining the recent innovation by Stokes et al where deep neural networks were used to find a novel antibiotic molecule.">
    <meta name="keywords" content="antibiotics, deep learning, chemprop, explained, halicin">
    <meta name="author" content="Stephan Heijl">

    <meta name="twitter:card" content="summary" />
    <meta name="twitter:site" content="@stephanheijl" />
    <meta name="twitter:title" content="Visualizing Deep Learning Antibiotics" />
    <meta name="twitter:description" content="This blog post visualizes and explains the technical side behind using deep learning to find novel antibiotics." />
    <meta name="twitter:image" content="https://stephanheijl.com/img/chemprop/MessagePassingConvNet.png" />

    <link href="https://fonts.googleapis.com/css2?family=Newsreader:ital,opsz,wght@0,6..72,400;0,6..72,500;1,6..72,400&family=Outfit:wght@300;400;500;600&family=JetBrains+Mono:wght@400&display=swap" rel="stylesheet">
    <link rel="stylesheet" href="style-v2.css">
    <style>
        .article-content table {
            width: 100%;
            border-collapse: collapse;
            margin: 2rem 0;
            font-size: 0.9rem;
        }
        .article-content thead {
            background: var(--bg-secondary);
            font-weight: 600;
        }
        .article-content th, .article-content td {
            padding: 0.75rem 1rem;
            text-align: left;
            border-bottom: 1px solid var(--border-subtle);
        }
        .article-content tr:hover {
            background: var(--bg-secondary);
        }
        .animation-embed {
            border: 0;
            height: 200px;
            width: 100%;
            max-width: 600px;
            margin: 2rem auto;
            display: block;
        }
        .animation-embed.tall {
            height: 310px;
            max-width: 700px;
        }
        .toc {
            background: var(--bg-secondary);
            padding: 2rem;
            margin: 2rem 0;
        }
        .toc ol {
            margin: 0;
            padding-left: 1.5rem;
        }
        .toc li {
            margin-bottom: 0.5rem;
        }
        .toc a {
            color: var(--text-secondary);
        }
        .toc a:hover {
            color: var(--accent-warm);
        }
    </style>
</head>
<body>
    <!-- Progress Bar -->
    <div class="progress-bar" id="progressBar"></div>

    <!-- Navigation -->
    <nav>
        <a href="index.html" class="logo">Stephan Heijl</a>
        <ul class="nav-links">
            <li><a href="projects.html">Work</a></li>
            <li><a href="projects.html#posts">Writing</a></li>
            <li><a href="projects.html#education">Background</a></li>
            <li><a href="contact.html">Contact</a></li>
        </ul>
    </nav>

    <!-- Article Header -->
    <header class="article-header">
        <div class="breadcrumb">
            <a href="index.html">Home</a>
            <span>-></span>
            <a href="projects.html#posts">Writing</a>
            <span>-></span>
            <span>Deep Learning Antibiotics</span>
        </div>

        <div class="article-meta">
            <span class="meta-tag">Case Study</span>
            <span class="meta-item">Posted: March 15, 2020</span>
            <span class="meta-item">Updated: March 23, 2020</span>
        </div>

        <h1>Visualizing and Explaining Deep Learning Antibiotics</h1>

        <p class="article-intro">
            On February 20th 2020, Stokes et al published "A Deep Learning Approach to Antibiotic Discovery" in Cell.
            This post dives into the technical aspects behind this discovery, with specific attention to the deep
            learning model used.
        </p>
    </header>

    <!-- Article Content -->
    <article class="article-content">
        <iframe src='/chemprop_animations/message_passing_animation.html' class="animation-embed"></iframe>

        <nav class="toc">
            <strong>Table of Contents</strong>
            <ol>
                <li><a href="#introduction">Introduction</a></li>
                <li><a href="#gnn">Graph Neural Networks</a></li>
                <li><a href="#chemprop">chemprop</a></li>
                <li><a href="#stokes">Stokes et al. Methodology</a></li>
                <li><a href="#discussion">Discussion</a></li>
                <li><a href="#conclusion">Conclusion</a></li>
            </ol>
        </nav>

        <figure class="article-figure">
            <img src="img/chemprop/MessagePassingConvNet.png" alt="Message Passing Convolutional Network Architecture"/>
        </figure>

        <h2 id="introduction">Introduction</h2>

        <p>
            The space of molecules wherein antibiotics may occur is large and becoming larger. Many antibiotic
            discovery programs choose to look inside large existing chemical libraries to find new leads. These
            chemical libraries are limited in several ways, as they do not sufficiently cover the chemical space
            and are prohibitively expensive to curate and expand.
        </p>

        <p>
            According to Stokes et al: <strong>"Since the implementation of high-throughput screening in the 1980s,
            no new clinical antibiotics have been discovered using this method."</strong> Most 'new' finds turn out
            to be structurally very similar to older antibiotics, which reduces their potential for effectiveness.
        </p>

        <p>
            The authors note that machine learning has advanced to the point where it may present an alternative
            to this approach. In 2016, researchers already reported generating representations of molecules from
            a chemical compound space using deep learning (Gomez-Bombarelli et al). The innovation of deep learning
            primarily lies in its ability to describe the chemicals itself, instead of relying on manually designed
            annotations.
        </p>

        <p>In short, the prediction procedure was as follows:</p>

        <ol>
            <li>A deep graph-based neural network was trained to predict growth inhibition of E. coli with a
            dataset of 2335 molecules.</li>
            <li>This model was used to predict E. coli growth inhibiting properties on the Drug Repurposing Hub
            library, containing 6111 different molecules. The model scores 51% true positive rate and 97% true
            negative rate. Halicin was one of the true positives.</li>
            <li>The results of the previous test were inserted into the library and the model was retrained.</li>
            <li>The model was then used to predict on a subset of the ZINC15 chemical library containing over
            170 million molecules.</li>
        </ol>

        <p>
            The neural network used is a message passing network called <strong>chemprop</strong>. It is publicly
            available on GitHub: <a href="https://github.com/chemprop/chemprop">github.com/chemprop/chemprop</a>.
        </p>

        <h2 id="gnn">Graph Neural Networks</h2>

        <h3>Molecules as Graphs</h3>

        <p>
            Molecules are groups of atoms held together by chemical bonds. Because all the atoms in a molecule
            are by definition (directly or indirectly) contiguous, it is easy to see how they could be converted
            into a graph. Atoms become nodes and the chemical bonds between them become vertices.
        </p>

        <figure class="article-figure">
            <img src="/img/chemprop/halicin.png" alt="Halicin molecular structure"/>
            <figcaption>Halicin (5-[(5-Nitro-1,3-thiazol-2-yl)sulfanyl]-1,3,4-thiadiazol-2-amine)</figcaption>
        </figure>

        <figure class="article-figure">
            <img src="/img/chemprop/halicin_network_nodes_color_edges.png" alt="Halicin as a colored graph"/>
            <figcaption>Halicin represented as a graph with colored nodes and edges</figcaption>
        </figure>

        <h3>Message Passing Neural Networks</h3>

        <p>
            Message Passing Neural Networks (MPNNs) take advantage of the ability of molecules to be represented
            as graphs to compute meaningful representations of them. Molecules vary in size and in the number of
            nodes and edges they have, which makes it difficult for neural networks to perform operations with them.
            Using MPNNs we can compute a fixed size representation.
        </p>

        <p>
            The MPNN computes its representation in two phases: A <strong>message passing phase</strong> and a
            <strong>readout phase</strong>. The former allows the network to iteratively build up properties of
            the molecule over a set amount of steps. The latter combines these properties into a fixed size vector.
        </p>

        <h4>Message Passing Phase</h4>

        <figure class="article-figure">
            <iframe src='/chemprop_animations/message_passing_animation.html' class="animation-embed"></iframe>
            <figcaption>Animation showing the message passing phase on a projection of Halicin</figcaption>
        </figure>

        <p>During the Message Passing Phase, each node and vertex in the graph has a hidden state. For every timestep:</p>

        <ol>
            <li>For every node, the message function is computed using the hidden state of said node, a neighbour
            node, and the vertex between them.</li>
            <li>This is repeated for every neighbour node. The messages are all summed.</li>
            <li>This message vector is run through an update function.</li>
            <li>When new vectors have been computed for every node, the hidden states are updated.</li>
            <li>This process is repeated for t iterations.</li>
        </ol>

        <h4>Readout Phase</h4>

        <p>
            The readout phase takes place after the full message passing phase completes. The hidden states of all
            nodes are passed into a readout function. The result is the representation of the molecule.
        </p>

        <h2 id="chemprop">chemprop</h2>

        <p>chemprop is a Message Passing Neural Network that builds upon the 2017 MPNN structure with several changes:</p>

        <ul>
            <li>Calculates messages over each vector instead of each node</li>
            <li>Includes molecule level annotations from RDKit</li>
            <li>Uses summation as an update function instead of a Gated Recurrent Unit</li>
            <li>Adds Dropout after each message passing step</li>
        </ul>

        <h3>Atom and Bond Features</h3>

        <p>The following features annotate each atom:</p>

        <table>
            <thead>
                <tr>
                    <th>Feature</th>
                    <th>Description</th>
                    <th>Dimensionality</th>
                </tr>
            </thead>
            <tbody>
                <tr>
                    <td>Type of atom</td>
                    <td>The type of atom (C, O, N, etc.)</td>
                    <td>One hot encoded, 100d</td>
                </tr>
                <tr>
                    <td>Number of bonds</td>
                    <td>Number of bonds the atom is involved in</td>
                    <td>Integer, 6d</td>
                </tr>
                <tr>
                    <td>Formal charge</td>
                    <td>Electronic charge assigned to an atom</td>
                    <td>Integer, 5d</td>
                </tr>
                <tr>
                    <td>Chirality</td>
                    <td>Mirror image superimposition</td>
                    <td>One hot encoded, 4d</td>
                </tr>
                <tr>
                    <td>Hybridization</td>
                    <td>Hybridization state</td>
                    <td>One hot encoded, 5d</td>
                </tr>
                <tr>
                    <td>Aromaticity</td>
                    <td>Whether atom is part of aromatic ring</td>
                    <td>Boolean, 1d</td>
                </tr>
                <tr>
                    <td>Atomic mass</td>
                    <td>Mass of atom divided by 100</td>
                    <td>Float, 1d</td>
                </tr>
            </tbody>
        </table>

        <figure class="article-figure">
            <img src="img/chemprop/periodic_table.png" alt="Periodic table with atomic masses"/>
            <figcaption>Periodic table with atomic masses below 1 labeled in blue</figcaption>
        </figure>

        <h3>Hyperparameter Optimization</h3>

        <p>chemprop supports hyperparameter optimization using Bayesian Optimization, tuning:</p>

        <ul>
            <li><strong>Model depth:</strong> Number of timesteps during message passing</li>
            <li><strong>Hidden size:</strong> Bond vector dimensions</li>
            <li><strong>Feed forward layers:</strong> Layers in the FFN following the MPNN</li>
            <li><strong>Dropout:</strong> Regularization in the MPNN</li>
        </ul>

        <figure class="article-figure">
            <iframe src='/chemprop_animations/message_propagation_animation.html' class="animation-embed tall"></iframe>
            <figcaption>Animation showing how model depth affects information propagation across the molecule</figcaption>
        </figure>

        <h2 id="stokes">Stokes et al. Methodology</h2>

        <h3>Architecture</h3>

        <p>The authors used chemprop with the following hyperparameters:</p>

        <ul>
            <li>Message passing steps: 6</li>
            <li>Neural Network hidden size: 2200</li>
            <li>Number of feed-forward layers: 3</li>
            <li>Dropout probability: 0.15</li>
        </ul>

        <p>An ensemble of 20 models was used to improve performance.</p>

        <h3>Dataset</h3>

        <p>
            Stokes et al initially measured the growth inhibition effects of 2335 different molecules. The growth
            inhibition was binarized with a cutoff of 80% inhibition, leading to 120 'hits'. Notable challenges:
        </p>

        <ol>
            <li><strong>Small dataset:</strong> Orders of magnitude smaller than typical image recognition datasets</li>
            <li><strong>Unbalanced:</strong> Only 5% of samples constitute hits</li>
        </ol>

        <h3>Halicin Mechanism of Action</h3>

        <p>
            The authors found that halicin retained its growth inhibiting activity even in antibiotic-resistant
            bacteria, suggesting an unconventional mechanism. RNA sequencing revealed that halicin affects the
            cell's ability to maintain an electrochemical gradient.
        </p>

        <figure class="article-figure">
            <img src="img/chemprop/halicin_ph.png" alt="Halicin effectiveness at different pH levels"/>
            <figcaption>Higher pH reduces halicin effectiveness, suggesting pH gradient involvement</figcaption>
        </figure>

        <h2 id="discussion">Discussion</h2>

        <h3>Dataset Imbalance</h3>
        <p>
            Using techniques like class weighting or bootstrapping could help rebalance the dataset and improve performance.
        </p>

        <h3>Pretraining chemprop</h3>
        <p>
            chemprop might benefit from a pre-training step where it predicts masked parts of molecules, similar
            to approaches in NLP. The vast number of available molecular structures could enable this.
        </p>

        <h3>Attention Mechanisms</h3>
        <p>
            Attention mechanisms allow neural networks to selectively focus on input parts. However, according
            to Kevin Yang (one of the main authors), they tried attention mechanisms without significant results.
        </p>

        <h2 id="conclusion">Conclusion</h2>

        <p>
            The authors made an important contribution to the intersection of machine learning and biology.
            Collaboration that applies innovations in deep learning to biology and healthcare will be an
            important source of new discoveries in the coming decade.
        </p>

        <p>
            It remains to be seen if halicin or other compounds will pass clinical trials, but given that the
            molecules are derived from existing drugs, their chances are substantial.
        </p>

        <h2>References</h2>

        <ul>
            <li>Stokes et al., Cell, February 20, 2020 - <a href="https://www.cell.com/cell/fulltext/S0092-8674(20)30102-1">Link</a></li>
            <li>Gomez Bombarelli et al., ACS Cent. Sci. 2018 - <a href="https://doi.org/10.1021/acscentsci.7b00572">Link</a></li>
            <li>Yang et al., J. Chem. Inf. Model. 2019 - <a href="https://doi.org/10.1021/acs.jcim.9b00237">Link</a></li>
        </ul>
    </article>

    <!-- Article Footer -->
    <div class="article-footer">
        <a href="projects.html#posts" class="back-link">
            <svg width="20" height="20" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="1.5">
                <path d="M19 12H5M12 19l-7-7 7-7"/>
            </svg>
            Back to Writing
        </a>
    </div>

    <!-- Related Posts -->
    <div class="related-posts">
        <div class="related-label">Related Posts</div>
        <div class="related-grid">
            <a href="rfdiffusion.html" class="related-card">
                <h3>A New Protein Design Era with Protein Diffusion</h3>
                <p>Exploring RFDiffusion and how diffusion models are revolutionizing protein design</p>
            </a>
            <a href="protein_sequence_ml.html" class="related-card">
                <h3>Using Sequence Data in Machine Learning</h3>
                <p>Practical techniques for encoding and processing protein sequences</p>
            </a>
        </div>
    </div>

    <!-- Footer -->
    <footer>
        <p class="footer-text">Â© 2024 Stephan Heijl</p>
        <div class="footer-links">
            <a href="https://github.com/StephanHeijl">GitHub</a>
            <a href="https://linkedin.com/in/stephanheijl">LinkedIn</a>
            <a href="contact.html">Email</a>
        </div>
    </footer>

    <script>
        // Reading progress bar
        window.addEventListener('scroll', () => {
            const docHeight = document.documentElement.scrollHeight - window.innerHeight;
            const scrollPos = window.scrollY;
            const progress = (scrollPos / docHeight) * 100;
            document.getElementById('progressBar').style.width = progress + '%';
        });
    </script>
    <script async defer src="https://sa.stephanheijl.com/app.js"></script>
    <noscript><img src="https://sa.stephanheijl.com/image.gif" alt=""></noscript>
</body>
</html>
